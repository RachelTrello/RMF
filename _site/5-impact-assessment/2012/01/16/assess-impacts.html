<!DOCTYPE html>
<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
      <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script>
      <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>


<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<link rel="stylesheet" href="/RMF/css/screen.css">
		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400italic,400,300italic,300,700,700italic|Open+Sans:400italic,600italic,700italic,700,600,400|Inconsolata:400,700">

		

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>5.3 Assessment Impacts | AI RMF Playbook</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="5.3 Assessment Impacts" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Assessment Impacts" />
<meta property="og:description" content="Assessment Impacts" />
<link rel="canonical" href="http://localhost:4000/RMF/5-impact-assessment/2012/01/16/assess-impacts.html" />
<meta property="og:url" content="http://localhost:4000/RMF/5-impact-assessment/2012/01/16/assess-impacts.html" />
<meta property="og:site_name" content="AI RMF Playbook" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2012-01-16T00:00:00+00:00" />
<script type="application/ld+json">
{"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/RMF/NISTlogo.png"}},"headline":"5.3 Assessment Impacts","dateModified":"2012-01-16T00:00:00+00:00","datePublished":"2012-01-16T00:00:00+00:00","@type":"BlogPosting","url":"http://localhost:4000/RMF/5-impact-assessment/2012/01/16/assess-impacts.html","description":"Assessment Impacts","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/RMF/5-impact-assessment/2012/01/16/assess-impacts.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/RMF/feed.xml" title="AI RMF Playbook" />

	</head>

	<body class="">
		<header>
			<div class="wrapper">
				<section class="top-bar">
					<div class="logo"><a href="/RMF/"></a></div>
					<a class="nav-toggle" id="open-nav" href="#">&#9776;</a>
<nav>
	
	
		
                
		  <a href="/RMF/" class="">HOME</a>
                
	
	
		
                
		  <a href="/RMF/govern.html" class="">GOVERN</a>
                
	
	
		
                
		  <a href="/RMF/map.html" class="">MAP</a>
                
	
	
		
                
                  <a class="">MEASURE</a>
                
	
	
		
                
                  <a class="">MANAGE</a>
                
	
	
		
                
		  <a href="/RMF/characteristics.html" class="">CHARACTERISTICS</a>
                
	
	
		
                
		  <a href="/RMF/terms.html" class="">TERMS</a>
                
	
</nav>

				</section>
				<section class="hero_search">
					<h1>AI Risk Managment Framework</h1>
					<h1>Playbook</h1>
					<form action="/RMF/search/" method="get">
	<input type="search" name="q"  placeholder="What would you like to know?" autofocus>
	<svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
	<input type="submit" value="Search" style="display: none;">
</form>
				</section>
			</div>

		</header>
		<section class="content">
			<div class="wrapper">
				<section class="tutorial">
	<section class="sidebar sticky">
		<ul>
			<li><a href="#question">Question</a></li>
			<li><a href="#how-can-my-organization-implement-this-sub-category">How can my organization implement this sub-category?</a></li>
			<li><a href="#ai-actors">AI actors</a></li>
			<li><a href="#ai-transparency-considerations-and-resources">AI Transparency considerations and resources</a></li>
			<li><a href="#what-is-this-sub-category-about">What is this sub-category about?</a></li>
			<li><a href="#where-might-i-go-to-learn-more">Where might I go to learn more?</a></li>

		</ul>
	</section>
	<section class="tutorial-content">
                
                <a href="/RMF/map.html">MAP</a>
                &nbsp/&nbsp
                
                <a href="/RMF/category/5-impact-assessment/">5 Impact Assessment</a>
	        <br>
                

                <h2> 5.3 Assessment Impacts </h2>


		<div class="tutorial-main">
                        
                            
                            

                           	 <h2 id="question"><span style="color:black;font-weight:360;font-size:26px">Question</span></h2>

<p>Have the potential harms been assessed in relation to the likelihood of such harms occurring and the expected benefits of the system?</p>

<p>If so, has this assessment been conducted by independent parties, either internally or externally?</p>

<h2 id="how-can-my-organization-implement-this-sub-category"><span style="color:black;font-weight:360;font-size:26px">How can my organization implement this sub-category?</span></h2>

<p>Review all documentation, including the stated purpose and benefit of the system and the mapped harms and their associated likelihoods.</p>

<p>Collaboratively determine which harms can be mitigated. Document mitigation plans.</p>

<p>Document the system’s estimated risk. Do not deploy (no-go), or decommission, the system if estimated risk surpasses organizational tolerances or thresholds. Otherwise (go), assign the system to an appropriate risk tier and oversight resources should be assigned in alignment with assessed risk.</p>

<h2 id="ai-actors"><span style="color:black;font-weight:360;font-size:26px"><a href="https://pages.nist.gov/RMF/terms.html">AI actors</a></span></h2>

<p>[Organizational management, AI deployment, Operators, Human factors, Domain experts]</p>

<h2 id="ai-transparency-considerations-and-resources"><span style="color:black;font-weight:360;font-size:26px">AI Transparency considerations and resources</span></h2>

<p><strong>Transparency Considerations – Key Questions: MAP 5.3</strong></p>
<ul>
  <li>To what extent do these policies foster public trust and confidence in the use of the AI system?</li>
  <li>What type of information is accessible on the design, operations, and limitations of the AI system to external stakeholders, including end users, consumers, regulators, and individuals impacted by use of the AI system?</li>
  <li>How has the entity identified and mitigated potential impacts of bias in the data, including inequitable or discriminatory outcomes?</li>
</ul>

<p><strong>AI Transparency Resources: MAP 5.3</strong></p>
<ul>
  <li>Datasheets for Datasets</li>
  <li>GAO-21-519SP: AI Accountability Framework for Federal Agencies &amp; Other Entities</li>
  <li>“AI policies and initiatives,” in Artificial Intelligence in Society, OECD, 2019</li>
  <li>Intel.gov: AI Ethics Framework for Intelligence Community  - 2020</li>
  <li>Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI - 2019</li>
</ul>

<h2 id="what-is-this-sub-category-about"><span style="color:black;font-weight:360;font-size:26px">What is this sub-category about?</span></h2>



                           	 
                           	 <input type="checkbox" class="read-more-state" id="/5-impact-assessment/2012/01/16/assess-impacts.html#what-is-this-sub-category-about"/>
                           	 <div class="read-more", id="/5-impact-assessment/2012/01/16/assess-impacts.html#what-is-this-sub-category-about">
                               		 

<p>The final output of risk triage is the go/no-go decision. This decision should take into account the mapped harms from previous steps, and the organizational capacity for their mitigation. This harms mapping step should also list system benefits beyond the status quo. The go/no-go decision can be made by an independent third-party or organizational management. For higher risk systems, it is often appropriate for technical or risk executives to be involved in the approval of go/no-go decisions. The decision to deploy should not be made by AI design and development teams, whose objective judgement may be hindered by the incentive to deploy.</p>


                           	 </div>
                                 <label for="/5-impact-assessment/2012/01/16/assess-impacts.html#what-is-this-sub-category-about" class="read-more-trigger"></label>

                           	 

<h2 id="where-might-i-go-to-learn-more"><span style="color:black;font-weight:360;font-size:26px">Where might I go to learn more?</span></h2>


                            
                           	 
                           	 <input type="checkbox" class="cont-more-state" id="/5-impact-assessment/2012/01/16/assess-impacts.html#where-might-i-go-to-learn-more" />
				 <div class="cont-more", id="/5-impact-assessment/2012/01/16/assess-impacts.html#where-might-i-go-to-learn-more">
                                	

<p>Board of Governors of the Federal Reserve System. SR 11-7: Guidance on Model Risk Management. (April 4, 2011). Retrieved on July 6, 2022 from <a href="https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm">Federal Reserve</a></p>

<p>Elisa Jillson. 2021. Aiming for truth, fairness, and equity in your company’s use of AI (April 19, 2021). Retrieved on July 7, 2022 from <a href="https://www.ftc.gov/business-guidance/blog/2021/04/aiming-truth-fairness-equity-your-companys-use-ai">FTC</a></p>

<p>Sarah Spiekermann and Till Winkler. 2020. Value-based Engineering for Ethics by Design. arXiv:2004.13676. Retrieved from <a href="https://arxiv.org/abs/2004.13676">arXiv:2004.13676</a></p>

<p>Sri Krishnamurthy. Quantifying Model Risk: Issues and approaches to measure and assess model risk when building quant models. QuantUniversity, Charlestown, MA. Retrieved on July 7, 2022 from <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.986.5412&amp;rep=rep1&amp;type=pdf">citeseerx.ist.psu.edu</a></p>

                           	 </div>
                                 <label for="/5-impact-assessment/2012/01/16/assess-impacts.html#where-might-i-go-to-learn-more" class="cont-more-trigger"></label>
                            

			

                </div>
                 
                <a href="/RMF//5-impact-assessment/2012/01/16/assess-impacts.html" class="back-to-top">Back to Top &uarr;</a>

	</section>
</section>




			</div>
		</section>

		<footer>
	<div class="wrapper">
		<p class="copyright">&copy; AI RMF Playbook Released July 2022. </p>
	</div>
</footer>


	</body>
</html>
