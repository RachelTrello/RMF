---
date: 2012-01-16
title: 1.4 Risk Tolerances
categories:
  - 1-Context
description: Risk Tolerances
type: Map
order_number: 4
---

## <span style="color:black;font-weight:360;font-size:26px">Question</span>

Have risk tolerances for the system been articulated?

## <span style="color:black;font-weight:360;font-size:26px">How can my organization implement this sub-category?</span>

Establish a maximum risk tolerance, beyond which systems are not deployed. 

Establish risk tiers for AI systems, with allocated oversight resources aligned to a system's risk tier. 

Do not deploy AI systems that exceed organizational risk tolerances or for "off-label" purposes.

Do not apply algorithmic models or AI-based systems to tasks or within social, domain, or organizational contexts for which they were not designed. Any attempt to do so should be approached with caution, especially in settings that organizations have deemed as high-risk. Document decisionmaking steps, especially in regards to risk-related trade-offs and system limitations.


## <span style="color:black;font-weight:360;font-size:26px">[AI actors](https://pages.nist.gov/RMF/terms.html)</span>

[Organizational management, AI design, AI development, AI deployment, TEVV]

## <span style="color:black;font-weight:360;font-size:26px">AI Transparency considerations and resources</span>

**Transparency Considerations â€“ Key Questions: MAP 1.4** 
- What justifications, if any, has the entity provided for the assumptions, boundaries, and limitations of the AI system?
- How has the entity identified and mitigated potential impacts of bias in the data, including inequitable or discriminatory outcomes?
- To what extent are the established procedures effective in mitigating bias, inequity, and other concerns resulting from the system?

**AI Transparency Resources: MAP 1.4**
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- WEF Model AI Governance Framework Assessment 2020
- Companion to the WEF Model AI Governance Framework- 2020

## <span style="color:black;font-weight:360;font-size:26px">What is this sub-category about?</span>

<!--more-->

Risk tolerance reflects the level and type of risk the organization will accept while conducting its mission and carrying out its strategy. The decision to implement and deploy a proposed AI system should not be pre-ordained, and should align with broader organizational risk tolerances, often established by boards of directors, compliance-focused executives or risk functions.  For each system, a go/no-go decision is made, perhaps at multiple points during the lifecycle of a system. Such decisions are best made in consultation with, but independent of stakeholders with a vested financial or reputational interest. For higher risk systems, it is often appropriate for technical or risk executives to be involved in the approval of go/no-go decisions. An affirmative organizational decision regarding risk tolerances for AI systems should be made, evaluated, and implemented on an ongoing basis, and tied to technical, business, and oversight functions so that appropriate risk-based decisions can be made about when to design, implement, deploy, decommission, or terminate a system.

<!--more-->

## <span style="color:black;font-weight:360;font-size:26px">Where might I go to learn more?</span>

<!--more-->

Board of Governors of the Federal Reserve System. SR 11-7: Guidance on Model Risk Management. (April 4, 2011). Retrieved on July 6, 2022 from https://www.federalreserve.gov/supervisionreg/srletters/sr1107.htm

The Office of the Comptroller of the Currency. Enterprise Risk Appetite Statement. (Nov. 20, 2019). Retrieved on July 12, 2022 from https://www.occ.treas.gov/publications-and-resources/publications/banker-education/files/pub-risk-appetite-statement.pdf
