---
date: 2012-01-16
title: 4.2 Risk Controls for Third Party Risks
categories:
  - 4-Third-Party
description: Risk Controls for Third Party Risk
type: Map
order_number: 2
---

## <span style="color:black;font-weight:360;font-size:26px">Question</span>

Have internal risk controls for third-party entities been documented and applied?

## <span style="color:black;font-weight:360;font-size:26px">How can my organization implement this sub-category?</span>

Supply inventory and approval methods, such as model documentation templates and software safelists. 

Conduct a risk review of third-party entities required for the AI system (including for data and models) related to bias, data privacy harms, and security vulnerabilities. 

Apply standard risk controls, such as procurement, security, and data privacy controls, to all acquired third-party technologies. 

Prepare for a review of AI system consultants and ensure that human resources (or other appropriate functions) are aware of their involvement. 

## <span style="color:black;font-weight:360;font-size:26px">[AI actors](https://pages.nist.gov/RMF/terms.html)</span>

[Organizational management, AI development, third-party entities, Human factors]

## <span style="color:black;font-weight:360;font-size:26px">AI Transparency considerations and resources</span>

**Transparency Considerations – Key Questions: MAP 4.2**
- Did you ensure that the AI system can be audited by independent third parties?
- To what extent do these policies foster public trust and confidence in the use of the AI system?
- Did you establish mechanisms that facilitate the AI system’s auditability (e.g. traceability of the development process, the sourcing of training data and the logging of the AI system’s processes, outcomes, positive and negative impact)?

**AI Transparency Resources: MAP 4.2**
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- WEF Model AI Governance Framework Assessment 2020
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI - 2019

## <span style="color:black;font-weight:360;font-size:26px">What is this sub-category about?</span>

<!--more-->

AI developers often access open-source, or otherwise freely available, third-party technologies. These technologies are known to have privacy, bias and security risks. Simply because a model, software, or data artifact is used commonly by AI system developers does not mean that it is free of risk.

Some institutions may not apply standard procurement, human resource, or other risk controls, to third-party AI entities in the same manner as for more standard technologies. In spite of - and due to - these difficulties, the importance of maintaining internal risk controls for third-party entities cannot be overstated.

<!--more-->

## <span style="color:black;font-weight:360;font-size:26px">Where might I go to learn more?</span>

<!--more-->

Office of the Comptroller of the Currency. 2021. Comptroller's Handbook: Model Risk Management, Version 1.0, August 2021. Retrieved on July 7, 2022 from [OCC](https://www.occ.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management/index-model-risk-management.html)

“Proposed Interagency Guidance on Third-Party Relationships: Risk Management,” 2021, available at [URL](https://www.occ.gov/news-issuances/news-releases/2021/nr-occ-2021-74a.pdf)


