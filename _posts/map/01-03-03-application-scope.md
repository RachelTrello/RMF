---
date: 2012-01-16
title: 3.3 Application Scope
categories:
  - 3-Benefits
description: Application Scope
type: Map
order_number: 3
---

## <span style="color:black;font-weight:360;font-size:26px">Question</span>

Has the scope of the system been narrowed to reasonably ensure it will only be used as intended and that risks can be managed properly?

## <span style="color:black;font-weight:360;font-size:26px">How can my organization implement this sub-category?</span>

Decide on narrow contexts in which a system will be deployed, such as limiting the time the system is deployed in between retrainings, targeting the geographical regions in which the system will operate, or defining clear user or stakeholder outcomes.

Define metrics by which internal and external validity, and bias in system outcomes will be measured, and establish expected thresholds or tolerances for those metrics. 

Involve legal or product policy teams in developing and enforcing guidelines or policies for managing risks and misuse due to downstream deployment by third parties. 

## <span style="color:black;font-weight:360;font-size:26px">[AI actors](https://pages.nist.gov/RMF/terms.html)</span>

[Organizational management, AI design, AI development, AI deployment, TEVV]

## <span style="color:black;font-weight:360;font-size:26px">AI Transparency considerations and resources</span>

**Transparency Considerations – Key Questions: MAP 3.**
- To what extent has the entity clearly defined technical specifications and requirements for the AI system?
- How do the technical specifications and requirements align with the AI system’s goals and objectives?
- How might you respond to an intelligence consumer asking “How do you know this?”

**AI Transparency Resources: MAP 3.1**
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI – 2019

## <span style="color:black;font-weight:360;font-size:26px">What is this sub-category about?</span>

<!--more-->

Once an AI system has been ideated, and its context and purpose mapped, its scope of application should be narrowed. Systems that function in a narrow scope tend to enable better mapping, measurement and management of risks, in both the learning or decision-making task, and in the system context. For example, open-ended chatbot systems that interact with the public on the internet have a large number of risks that may be difficult to map, measure and manage due to the variability from both the decision-making task and the operational context. A narrow application scope also helps ease oversight functions and related resources within an organization.

<!--more-->

## <span style="color:black;font-weight:360;font-size:26px">Where might I go to learn more?</span>

<!--more-->

Mark J. Van der Laan and Sherri Rose (2018). Targeted Learning in Data Science. Cham: Springer International Publishing, 2018.

Alice Zheng. 2015. Evaluating Machine Learning Models (2015). O'Reilly. Retrieved from https://www.oreilly.com/library/view/evaluating-machine-learning/9781492048756/.

Brenda Leong and Patrick Hall (2021). 5 things lawyers should know about artificial intelligence. ABA Journal. Retrieved from https://www.abajournal.com/columns/article/5-things-lawyers-should-know-about-artificial-intelligence.
