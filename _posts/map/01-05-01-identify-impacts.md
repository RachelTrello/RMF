---
date: 2012-01-16
title: 5.1 Identify Impacts
categories:
  - 5-Impact-Assessment
description: Identify Impacts
type: Map
order_number: 1
---

## <span style="color:black;font-weight:360;font-size:26px">Question</span>

Have the broader impacts of the system been assessed in relationship to potential users, organizations or society as a whole?

## <span style="color:black;font-weight:360;font-size:26px">How can my organization implement this sub-category?</span>

Standardize stakeholder engagement processes at the earliest stages of system formulation to identify potential impacts from the AI system on individuals, groups, communities, organizations, and society.

Employ methods such as value sensitive design (VSD) to identify baseline organizational and societal values for evaluating alignment/misalignment of system implementation and impact. 

Identify transparent approaches to seek, capture, and incorporate input from system users and other key stakeholders to assist with monitoring impacts and emergent risks. 

Incorporate quantitiative, qualitative, and mixed methods in the assessment and documentation of potential impacts for individuals, groups, communities, organizations, and society. 

Identify a team (internal or external) that is independent of AI design and development functions to assess the impact and likelihood of potential harms in relation to the expected benefits of the system. 

Define impact assessment processes that incorporate socio-technical elements and methods, and plan to normalize across organizational culture. 

Review and refine impact assessments once completed.

## <span style="color:black;font-weight:360;font-size:26px">[AI actors](https://pages.nist.gov/RMF/terms.html)</span>

[Organizational management, AI design, AI development, AI deployment, Human factors, Impact assessment]

## <span style="color:black;font-weight:360;font-size:26px">AI Transparency considerations and resources</span>

**Transparency Considerations – Key Questions: MAP 5.1**
- If it relates to people, does it unfairly advantage or disadvantage a particular social group? In what ways? How was this mitigated?
- If it relates to other ethically protected subjects, have appropriate obligations been met? (e.g., medical data might include information collected from animals)
- If it relates to people, could this dataset expose people to harm or legal action? (e.g., financial social or otherwise) What was done to mitigate or reduce the potential for harm?

**AI Transparency Resources: MAP 5.1**
- Datasheets for Datasets
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- “AI policies and initiatives,” in Artificial Intelligence in Society, OECD, 2019
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI - 2019

## <span style="color:black;font-weight:360;font-size:26px">What is this sub-category about?</span>

<!--more-->

As AI systems are socio-technical in nature, they are likely to have implications that extend beyond the stated purpose. These broader impacts can be classified as positive, neutral, or negative. Impacts can affect individuals, groups, communities, organizations, and society, as well as the environment, or national security. Assessing potential impacts in the mapping stage provides a baseline for system monitoring, enables adapting of tradeoffs between positive and adverse impacts, and detection of emergent risks. Impact assessments also enable risk management and mitigation, and provides an opportunity to capture new value which may arise from AI system use.

Different stakeholder groups may be aware of, or experience, benefits or harms that are unknown to internal system designers and can share their perspectives to inform an improved system design. Stakeholder feedback during system operation is also important for monitoring emergent risks that are newly introduced or amplified by AI systems, or may not be easily recognized or detected by internal technical teams.

<!--more-->

## <span style="color:black;font-weight:360;font-size:26px">Where might I go to learn more?</span>

<!--more-->

Susanne Vernim, Harald Bauer, Erwin Rauch, et al. 2022. A value sensitive design approach for designing AI-based worker assistance systems in manufacturing. Procedia Comput. Sci. 200, C (2022), 505–516. [DOI](https://doi.org/10.1016/j.procs.2022.01.248)

Harini Suresh and John V. Guttag. 2020. A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle. arXiv:1901.10002. Retrieved from [arXiv:1901.10002](https://arxiv.org/abs/1901.10002)

Margarita Boyarskaya, Alexandra Olteanu, and Kate Crawford. 2020. Overcoming Failures of Imagination in AI Infused System Development and Deployment. arXiv:2011.13416. Retrieved from [arXiv:2011.13416()]https://arxiv.org/abs/2011.13416)

Konstantinia Charitoudi and Andrew Blyth. A Socio-Technical Approach to Cyber Risk Management and Impact Assessment. Journal of Information Security 4, 1 (2013), 33-41. [DOI:](http://dx.doi.org/10.4236/jis.2013.41005)

Raji, I.D., Smart, A., White, R.N., Mitchell, M., Gebru, T., Hutchinson, B., Smith-Loud, J., Theron, D., & Barnes, P. (2020). Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic auditing. Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency.

Emanuel Moss, Elizabeth Anne Watkins, Ranjit Singh, Madeleine Clare Elish, & Jacob Metcalf. 2021. Assemlbing Accountability: Algorithmic Impact Assessment for the Public Interest.  Data & Society. Accessed 7/14/2022 at [Link](https://datasociety.net/library/assembling-accountability-algorithmic-impact-assessment-for-the-public-interest/)

Ada Lovelace Institute. 2022. Algorithmic Impact Assessment: A Case Study in Healthcare. Accessed July 14, 2022. [adalovelaceinstitute](https://www.adalovelaceinstitute.org/report/algorithmic-impact-assessment-case-study-healthcare/)

Microsoft. Responsible AI Impact Assessment Template. 2022. Accessed July 14, 2022. [Microsoft-RAI-Impact-Assessment-Template](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Template.pdf)

Microsoft. Responsible AI Impact Assessment Guide. 2022. Accessed July 14, 2022. [Microsoft-RAI-Impact-Assessment-Guide](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Guide.pdf)
