---
date: 2012-01-16
title: 3.1 System Benefits
categories:
  - 3-Benefits
description: System Benefits
type: Map
order_number: 1
---

## <span style="color:black;font-weight:360;font-size:26px">Question</span>

Column C

## <span style="color:black;font-weight:360;font-size:26px">How can my organization implement this sub-category?</span>

Perform a context analysis to list and assess specific negative impacts arising from a lack of trustworthy characteristics, including:

* Negative impacts are mapped to confusion matrix elements, e.g., true positives and true negative decisions leading to feedback loops and a lack of reliability, or false positives or false negatives leading to safety risks.
* Negative impacts are mapped to numeric over- and under-prediction, e.g., a lack of robustness leads to frequent numeric under-prediction and undervaluing of assets.
* Denigration, erasure, exnomination, misrecognition, stereotyping, underrepresenation and other content harms leading to biased or unfair outcomes are mapped.
* If negative impacts are not direct or obvious, teams should engage in structured discussions with external stakeholders to document responses to:
    * Who could be harmed?
    * What could be harmed?
    * When could harm arise?
    * How could harm arise?

Conduct context analysis and elicit and document stakeholder requirements using resources such as software engineering and product management guidance, user stories, user interaction/user experience (UI/UX) research; and document relevant technical and socio-technical trustworthy characteristics (such as ML-specific security vulnerabilities or recourse mechanisms for end-users).

Provide robust processes and resources to AI designers and developers for enumeration of negative impacts in conjuction with system requirements, or for review or audit of harms mitigation once a system is deployed.

Implement processes to evaluate qualitative and quantitative costs of internal and external failures of AI systems, with linkages to actions for prevention, detection, and/or correction of potential risks and related impacts. Evaluate failure costs to inform go/no-go decisions at all stages of the AI system lifecycle.

## <span style="color:black;font-weight:360;font-size:26px">[AI actors](https://pages.nist.gov/RMF/terms.html)</span>

Column G

## <span style="color:black;font-weight:360;font-size:26px">AI Transparency considerations and resources</span>

Column H

## <span style="color:black;font-weight:360;font-size:26px">What is this sub-category about?</span>

<!--more-->

Column D

<!--more-->

## <span style="color:black;font-weight:360;font-size:26px">Where might I go to learn more?</span>

<!--more-->

Column F

