---
date: 2012-01-16
title: 4.1 Document Third Party Risks
categories:
  - 4-Third-Party
description: Document Third Party Risks
type: Map
order_number: 1
---

## <span style="color:black;font-weight:360;font-size:26px">Question</span>

Have risks in the third-party entities been mapped, triaged and documented?

## <span style="color:black;font-weight:360;font-size:26px">How can my organization implement this sub-category?</span>

Review audit reports, testing results, product roadmaps, warranites, terms of service, end-user license agreements, contracts and other documentation related to third-party entities that can assist in value assessment and risk management. 

Review third-party software release schedules and software change management plans (hotfixes, patches, updates, forward- and backward- compatibility guarantees) for irregularities.  

Review potential technology and human redunancies to address third-party entity failures. 

Inventory third-party entities (hardware, open-source software, foundation models, open source data, proprietary software, proprietary data, etc.) necessary for implementation and maintenance of the system.

## <span style="color:black;font-weight:360;font-size:26px">[AI actors](https://pages.nist.gov/RMF/terms.html)</span>

[Organizational management, AI development, third-party entities, AI deployment, Human factors]

## <span style="color:black;font-weight:360;font-size:26px">AI Transparency considerations and resources</span>

**Transparency Considerations â€“ Key Questions: MAP 4.1**
- Did you establish a process for third parties (e.g. suppliers, end-users, subjects, distributors/vendors or workers) to report potential vulnerabilities, risks or biases in the AI system? 
- If your organization obtained datasets from a third party, did your organization assess and manage the risks of using such datasets?
- How will the results independently verified?

**AI Transparency Resources: MAP 4.1**
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- WEF Model AI Governance Framework Assessment 2020

## <span style="color:black;font-weight:360;font-size:26px">What is this sub-category about?</span>

<!--more-->

Risks from third-party technologies and personnel are often more difficult to map, as AI technologies are particularly complex or opaque and third-party organization risk tolerances or values may not align to those of the consuming institution. In spite of - and due to - these difficulties, the importance of managing and transparently documenting the risk of third-party technologies and personnel cannot be overstated. Commercial, open source and other freely-available technologies should be screened for third-party risks. 

For example, foundation models are popular with AI developers due to their ease of use for inference tasks. These models tend to rely on large uncurated web datasets, which often have undisclosed origins - raising concerns about privacy, bias, and unintended effects. Other risks may arise due to increased levels of statistical uncertainty, difficulty with reproducibility, and issues with scientific validity. Bias incidents have been reported in relation to use of these models. 

<!--more-->

## <span style="color:black;font-weight:360;font-size:26px">Where might I go to learn more?</span>

<!--more-->

**Foundation models**

Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ðŸ¦œ. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT '21). Association for Computing Machinery, New York, NY, USA, 610â€“623. [Link](https://doi.org/10.1145/3442188.3445922)

Julia Kreutzer, Isaac Caswell, Lisa Wang, et al. 2022. Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets. Transactions of the Association for Computational Linguistics 10 (2022), 50â€“72.  [DOI:](https://doi.org/10.1162/tacl_a_00447)

Laura Weidinger, Jonathan Uesato, Maribeth Rauh, et al. 2022. Taxonomy of Risks posed by Language Models. In 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT '22). Association for Computing Machinery, New York, NY, USA, 214â€“229. [Link](https://doi.org/10.1145/3531146.3533088)

Office of the Comptroller of the Currency. 2021. Comptroller's Handbook: Model Risk Management, Version 1.0, August 2021. Retrieved on July 7, 2022 from [OCC](https://www.occ.gov/publications-and-resources/publications/comptrollers-handbook/files/model-risk-management/index-model-risk-management.html)

Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, et al. 2021. On the Opportunities and Risks of Foundation Models. arXiv:2108.07258. Retrieved from [arXiv:2108.07258](https://arxiv.org/abs/2108.07258)
