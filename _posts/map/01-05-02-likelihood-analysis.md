---
date: 2012-01-16
title: 5.2 Likelihood Analysis
categories:
  - 5-Impact-Assessment
description: Likelihood Analysis
type: Map
order_number: 2
---

## <span style="color:black;font-weight:360;font-size:26px">Question</span>

Has the likelihood of each harm been evaluated?

## <span style="color:black;font-weight:360;font-size:26px">How can my organization implement this sub-category?</span>

Define assessment scales for measuring impact. Scales may be qualitative, such as red-amber-green (RAG), or may entail simulations or econometric approaches. Document and apply scales uniformly to different AI systems within an organization's purview. 

Plan to apply impact assessments at a specific frequency at key stages in the AI lifecycle, connected to the harm a system can cause and how quickly a system changes. 

Assess the benefits and potential negative impacts of the specific system in relation to false positive, false negatives, true positives and true negatives (e.g.: for binary classification systems), or for numeric over- and under-prediction. (e.g.: for continuous outcomes). 

Review ratings for each impact listed in the assessment. 

Define scales by which probability is assessed. Scales may be qualitative, such as red-amber-green (RAG), or may entail simulations or econometric approaches. Document and apply scales uniformly to different AI systems within an organization's purview. 

Apply the agreed upon scale to the system and assess the likelihood of harms using the scale. Document likelihood estimates. 

Review likelihood estimates for each listed impact in the assessment.

## <span style="color:black;font-weight:360;font-size:26px">[AI actors](https://pages.nist.gov/RMF/terms.html)</span>

[Organizational management, AI design, AI development, AI deployment, Impact assessment, Human factors, TEVV]

## <span style="color:black;font-weight:360;font-size:26px">AI Transparency considerations and resources</span>

**Transparency Considerations – Key Questions: MAP 5.2**
- Which population(s) does the AI system impact?
- What assessments has the entity conducted on data security and privacy impacts associated with the AI system?
- Did you ensure that the AI system can be audited by independent third parties?

**AI Transparency Resources: MAP 5.2**
- Datasheets for Datasets
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- “AI policies and initiatives,” in Artificial Intelligence in Society, OECD, 2019
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- Assessment List for Trustworthy AI (ALTAI) - The High-Level Expert Group on AI - 2019

## <span style="color:black;font-weight:360;font-size:26px">What is this sub-category about?</span>

<!--more-->

After identifying potential AI system impacts the likelihood of a given impact should be evaluated and risk triage considered. These probability estimates are then assessed and judged for go/no-go decision. If an organization deploys the system, the likelihood estimate can be used to assign appriopriate oversight resources in accordance with risk level.

<!--more-->

## <span style="color:black;font-weight:360;font-size:26px">Where might I go to learn more?</span>

<!--more-->

Emilio Gómez-González and Emilia Gómez. 2020. Artificial intelligence in medicine and healthcare. Joint Research Centre (European Commission). Retrieved from [op.europa.eu](https://op.europa.eu/en/publication-detail/-/publication/b4b5db47-94c0-11ea-aac4-01aa75ed71a1/language-en)

Artificial Intelligence Incident Database. 2022. Retrieved from [Incidentdatabase](https://incidentdatabase.ai/?lang=en)
