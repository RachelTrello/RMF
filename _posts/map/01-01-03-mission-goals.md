---
date: 2012-01-16
title: 1.3 Mission Goals
categories:
  - 1-Context
description: Mission Goals
type: Map
order_number: 3
---

## <span style="color:black;font-weight:360;font-size:26px">Question</span>

Does the purpose of the AI system, and its interactions with its context, align to organizations values? 

## <span style="color:black;font-weight:360;font-size:26px">How can my organization implement this sub-category?</span>

Review and/or reject documented concerns about context and the system's purpose as related to organization's stated values, as defined by mission statements, corporate social responsibility commitments, or AI principles. Reconsider design, implementation, or deployment of AI systems that may lead to impacts which do not reflect institutional values. 

## <span style="color:black;font-weight:360;font-size:26px">[AI actors](https://pages.nist.gov/RMF/terms.html)</span>

[Organizational management]

## <span style="color:black;font-weight:360;font-size:26px">AI Transparency considerations and resources</span>

**Transparency Considerations – Key Questions: MAP 1.3** 
- What goals and objectives does the entity expect to achieve by designing, developing, and/or deploying the AI system?
- To what extent are the model outputs consistent with the entity’s values and principles to foster public trust and equity?
- To what extent are the metrics consistent with system goals, objectives, and constraints, including ethical and compliance considerations?

**AI Transparency Resources: MAP 1.3**
- GAO-21-519SP: AI Accountability Framework for Federal Agencies & Other Entities
- Intel.gov: AI Ethics Framework for Intelligence Community  - 2020
- WEF Model AI Governance Framework Assessment 2020
- “Including Insights from the Comptroller General’s Forum on the Oversight of Artificial Intelligence An Accountability Framework for Federal Agencies and Other Entities,” 2021

## <span style="color:black;font-weight:360;font-size:26px">What is this sub-category about?</span>

<!--more-->

Socio-technical AI risks emerge from the interplay of technical development decisions and how a system is used, who operates it, and the social context into which it is deployed.

<!--more-->

## <span style="color:black;font-weight:360;font-size:26px">Where might I go to learn more?</span>

<!--more-->

Algorithm Watch. AI Ethics Guidelines Global Inventory. Retrieved from https://inventory.algorithmwatch.org/

Emanuel Moss and Jacob Metcalf. 2020. Ethics Owners: A New Model of Organizational Responsibility in Data-Driven Technology Companies. Data & Society Research Institute. Retrieved from https://datasociety.net/pubs/Ethics-Owners.pdf

Future of Life Institute. Asilomar AI Principles. Retrieved from https://futureoflife.org/2017/08/11/ai-principles/

Leonard Haas, Sebastian Gießler, and Veronika Thiel. 2020. In the realm of paper tigers – exploring the failings of AI ethics guidelines. (April 28, 2020). Retrieved on July 6, 2022 from https://algorithmwatch.org/en/ai-ethics-guidelines-inventory-upgrade-2020/
